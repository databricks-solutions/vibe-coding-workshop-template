# Repository Navigator (Quick Reference)

> **This file is the universal entry point for any AI coding assistant** — Cursor, Claude Code, Windsurf, Copilot, Codex, or any agent that reads `AGENTS.md`.

This is a **monorepo** with three components: a Databricks App with Lakebase, a Data Product Accelerator with 59 agent skills, and an Agentic Framework for building multi-agent systems.

---

## Project Layout

```
vibe-coding-workshop-template/          <-- workspace root / agent CWD
├── AGENTS.md                           <-- THIS FILE (root navigator)
├── README.md                           <-- Human-readable project overview
├── QUICKSTART.md                       <-- Quick-start guide (two pathways)
├── PRE-REQUISITES.md                   <-- Workshop prerequisites checklist
├── env.example                         <-- Environment variable template
│
├── apps_lakebase/                      <-- Component 1: Databricks App (FastAPI + Lakebase)
│   ├── app.yaml                        #   App entry point config
│   ├── pyproject.toml                  #   Python dependencies
│   ├── server/                         #   FastAPI backend
│   │   ├── app.py                      #     Main application
│   │   └── routers/                    #     API + health endpoints
│   ├── scripts/                        #   Setup, deploy, local dev scripts
│   └── lakebase/                       #   Lakebase DDL/DML reference
│
├── agentic-framework/                  <-- Component 2: Multi-Agent Build Framework
│   ├── agents/                         #   Agent prompts (PRD analyzer, skill scaffolder, etc.)
│   └── skills/
│       └── foundation-model-agent-loop/
│           └── SKILL.md                #   Tool-calling loop with Foundation Models
│
├── data_product_accelerator/           <-- Component 3: 59 Agent Skills for Data Products
│   ├── AGENTS.md                       #   *** DETAILED SKILL ROUTING TABLE ***
│   ├── QUICKSTART.md                   #   One-prompt-per-stage guide
│   ├── README.md                       #   Accelerator overview
│   ├── context/                        #   Customer schema CSV inputs
│   ├── skills/                         #   59 skills across 12 domains
│   └── docs/                           #   Framework design documentation
│
├── gold_layer_design/                  <-- GENERATED by Gold Design skill
├── src/                                <-- GENERATED by implementation skills
├── plans/                              <-- GENERATED by Planning skill
├── resources/                          <-- GENERATED by Asset Bundle skills
└── databricks.yml                      <-- GENERATED by Asset Bundle skills
```

| Direction | Location | Examples |
|-----------|----------|----------|
| **Read from** (framework) | `apps_lakebase/`, `agentic-framework/`, `data_product_accelerator/` | Skills, manifests, server code, docs |
| **Write to** (artifacts) | Repository root | `gold_layer_design/`, `src/`, `plans/`, `resources/`, `databricks.yml` |

> **Rule:** Generated artifact paths (`gold_layer_design/`, `src/`, `plans/`, `resources/`, `databricks.yml`) are relative to the repository root. Never create generated files inside `data_product_accelerator/`, `apps_lakebase/`, or `agentic-framework/`.

---

## Component Routing

**MANDATORY:** Before starting any task, match keywords below to find the right component. Read the linked file FIRST.

### Data Product Accelerator — `data_product_accelerator/AGENTS.md`

| Keywords | Action |
|----------|--------|
| "medallion architecture", "data product", "lakehouse", "data platform" | Read `data_product_accelerator/AGENTS.md` |
| "bronze layer", "test data", "Faker", "demo data", "source tables" | Read `data_product_accelerator/AGENTS.md` |
| "silver layer", "DLT", "expectations", "data quality", "DQX" | Read `data_product_accelerator/AGENTS.md` |
| "gold layer", "dimensional model", "ERD", "YAML schema", "merge scripts" | Read `data_product_accelerator/AGENTS.md` |
| "Genie Space", "semantic layer", "metric view", "TVF" | Read `data_product_accelerator/AGENTS.md` |
| "monitoring", "dashboard", "alert", "observability", "anomaly detection" | Read `data_product_accelerator/AGENTS.md` |
| "MLflow", "ML model", "training", "inference", "ML pipeline" | Read `data_product_accelerator/AGENTS.md` |
| "GenAI agent", "ResponsesAgent", "AI agent", "evaluation" | Read `data_product_accelerator/AGENTS.md` |
| "schema CSV", "bootstrap", "new project", "build data platform" | Read `data_product_accelerator/AGENTS.md` |
| "project plan", "architecture plan", "planning" | Read `data_product_accelerator/AGENTS.md` |
| "Asset Bundle", "DAB", "deploy pipeline", "job YAML" | Read `data_product_accelerator/AGENTS.md` |
| "naming", "tagging", "PII", "PK/FK", "constraints", "table properties" | Read `data_product_accelerator/AGENTS.md` |

### Databricks App — `apps_lakebase/`

| Keywords | Read This |
|----------|-----------|
| "FastAPI", "backend", "server", "API endpoint", "routers" | `apps_lakebase/server/app.py`, `apps_lakebase/server/routers/` |
| "Lakebase", "PostgreSQL", "database tables", "DDL", "DML" | `apps_lakebase/lakebase/README.md`, `apps_lakebase/scripts/setup-lakebase.sh` |
| "deploy app", "app.yaml", "Databricks Apps" | `apps_lakebase/app.yaml`, `apps_lakebase/scripts/deploy.sh` |
| "setup", "authentication", "PAT", "CLI profile" | `apps_lakebase/scripts/setup.sh`, `env.example` |
| "local dev", "hot reload", "run local", "watch" | `apps_lakebase/scripts/watch.sh`, `apps_lakebase/scripts/run_local.sh` |
| "health check", "readiness", "liveness" | `apps_lakebase/server/routers/health.py` |
| "dependencies", "pyproject.toml", "requirements" | `apps_lakebase/pyproject.toml` |
| "app status", "app logs" | `apps_lakebase/scripts/app_status.sh` |

### Agentic Framework — `agentic-framework/`

| Keywords | Read This |
|----------|-----------|
| "multi-agent", "Foundation Model", "tool-calling loop", "agent loop" | `agentic-framework/skills/foundation-model-agent-loop/SKILL.md` |
| "PRD", "product requirements", "analyze PRD" | `agentic-framework/agents/prd-analyzer.md` |
| "scaffold skill", "create skill", "SKILL.md template" | `agentic-framework/agents/skill-scaffolder.md` |
| "build tool", "Python tool", "agent tool" | `agentic-framework/agents/tool-builder.md` |
| "test agent", "agent behavior test" | `agentic-framework/agents/agent-tester.md` |
| "agent UI", "wire agent to UI", "frontend agent" | `agentic-framework/agents/agent-ui-wiring-prompt.md` |
| "multi-agent orchestrator", "orchestrator build" | `agentic-framework/agents/multi-agent-build-prompt.md` |
| "deploy agent", "agent deployment" | `agentic-framework/agents/databricks-deployer.md` |

---

## Data Product Accelerator — 9-Stage Pipeline (Quick Reference)

For data product, medallion architecture, or Lakehouse tasks, the Data Product Accelerator provides a **Design-First Pipeline** with 59 agent skills. Read `data_product_accelerator/AGENTS.md` for the full routing table.

```
data_product_accelerator/context/*.csv
  → (1) Gold Design      — dimensional model, ERDs, YAML schemas
  → (2) Bronze           — source tables + test data (Faker)
  → (3) Silver           — DLT pipelines + data quality
  → (4) Gold Impl        — tables, merges, constraints
  → (5) Planning         — phase plans + manifest contracts
  → (6) Semantic Layer   — Metric Views, TVFs, Genie Spaces
  → (7) Observability    — monitors, dashboards, alerts
  → (8) ML               — experiments, training, inference
  → (9) GenAI Agents     — agents, evaluation, deployment
```

| Stage | Keywords | Skill Entry Point |
|-------|----------|-------------------|
| 1 | "new project", "schema CSV", "Gold design", "ERD" | `data_product_accelerator/skills/gold/00-gold-layer-design/SKILL.md` |
| 2 | "Bronze", "test data", "Faker" | `data_product_accelerator/skills/bronze/00-bronze-layer-setup/SKILL.md` |
| 3 | "Silver", "DLT", "expectations" | `data_product_accelerator/skills/silver/00-silver-layer-setup/SKILL.md` |
| 4 | "Gold tables", "merge scripts" | `data_product_accelerator/skills/gold/01-gold-layer-setup/SKILL.md` |
| 5 | "project plan", "architecture plan" | `data_product_accelerator/skills/planning/00-project-planning/SKILL.md` |
| 6 | "metric view", "TVF", "Genie Space" | `data_product_accelerator/skills/semantic-layer/00-semantic-layer-setup/SKILL.md` |
| 7 | "monitoring", "dashboard", "alert" | `data_product_accelerator/skills/monitoring/00-observability-setup/SKILL.md` |
| 8 | "MLflow", "ML model", "training" | `data_product_accelerator/skills/ml/00-ml-pipeline-setup/SKILL.md` |
| 9 | "GenAI agent", "ResponsesAgent" | `data_product_accelerator/skills/genai-agents/00-genai-agents-setup/SKILL.md` |

**New project?** Start at stage 1: place your schema CSV in `data_product_accelerator/context/`, then read `data_product_accelerator/skills/gold/00-gold-layer-design/SKILL.md`.

---

## Key Rules

1. **Route first, act second.** Match keywords in the tables above, then read the linked file before writing any code.
2. **Read the component-level AGENTS.md or README.md FIRST** — each component owns its own detailed routing.
3. **Generated artifacts go at the repo root** — never inside `data_product_accelerator/`, `apps_lakebase/`, or `agentic-framework/`.
4. **Framework content is read-only** — skills, manifests, and server code are inputs; do not modify them unless explicitly asked.
5. **For data product tasks**, always defer to `data_product_accelerator/AGENTS.md` — it contains the full 59-skill routing table.

---

## IDE Compatibility

This framework is built on the open [Agent Skills (SKILL.md)](https://agentskills.io) format and works with any AI coding assistant that can read files.

| IDE / Agent | How It Discovers This File | File Reference Syntax |
|-------------|---------------------------|----------------------|
| **Cursor** | Auto-loads `AGENTS.md` | `@path/to/file` |
| **Claude Code** | Reads `AGENTS.md` (or `CLAUDE.md`) at repo root | Reference files by path in conversation |
| **Windsurf** | Reads `AGENTS.md` or `.windsurfrules` at repo root | `@path/to/file` |
| **Copilot** | Reads `AGENTS.md` or `.github/copilot-instructions.md` | `#file:path/to/file` |
| **Codex** | Reads `AGENTS.md` at repo root | Reference files by path |
| **Other** | Point the agent to this file manually | Paste file contents or path |

---

## Prompting Patterns (All IDEs)

### Data Product Accelerator

```
I have a customer schema at @data_product_accelerator/context/booking_app_schema.csv.
Please design the Gold layer using @data_product_accelerator/skills/gold/00-gold-layer-design/SKILL.md
```

### Databricks App

```
Add a new API endpoint to the Databricks App.
Read @apps_lakebase/server/routers/api.py and add a GET /recommendations endpoint.
```

### Agentic Framework

```
Build a multi-agent orchestrator using Databricks Foundation Models.
Read @agentic-framework/skills/foundation-model-agent-loop/SKILL.md for the tool-calling pattern.
```

If your IDE doesn't support `@` references, paste the file path or ask the agent to read it:

```
Read the file data_product_accelerator/AGENTS.md and follow its routing instructions.
```
